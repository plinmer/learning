# 消息不重复不丢



# 数据挤压如何处理，参考(https://www.bilibili.com/video/BV1LR4y1B7ui/?spm_id_from=333.788&vd_source=9bbaae8bc6b983e622d9599373de32ad)
Kafka 线上大量消息积压可能是由于多种原因引起的，例如消费者处理能力不足、生产者发送速度过快、Kafka 集群配置不当等。针对不同的原因，可以采取不同的处理措施。
- 增加消费者数量  
    如果消息积压是由于消费者处理能力不足引起的，可以考虑增加消费者数量来分担负载。可以采用横向扩展的方式，增加消费者实例的数量，或者调整消费者的配置来提高消费能力。
    这样会导致同一个分区被多个消费者消费
    另一种方案是consumer消费的数据放到一个内存队列中，下游创建线程去消费队列中的数据。这样也会有不一致问题？？
- 批量消费数据  
- 优化生产者发送速度  
    如果消息积压是由于生产者发送速度过快引起的，可以考虑优化生产者的发送速度，例如增加生产者实例的数量、调整生产者的配置参数等。
- 调整Kafka集群配置  
    如果消息积压是由于Kafka集群配置不当引起的，可以考虑调整 Kafka 集群的配置参数，例如增加 Kafka 集群的分区数量、扩容 Kafka 集群的节点数量、调整Kafka的存储策略等。
- 增加存储容量：如果消息积压是由于存储容量不足引起的，可以考虑增加存储容量，例如扩容 Kafka 集群的存储节点、使用更大容量的磁盘等。
- 增加下游线程数
    谁来提交offset呢？？
- 增加partition数量
    直接增加partition数据可能会导致同一个topic划分到不同的分区，破坏数据的顺序性（比如同一个userid的操作分到两个分区，造成下游消费数据的顺序不一致）
- 增加新的topic
    通过增加新的topic来增加partition，这种方法可能不太好，下游业务需要支持兼容
